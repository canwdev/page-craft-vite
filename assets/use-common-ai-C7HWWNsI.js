import{by as e,L as t,A as a,G as s,aF as o}from"./index-BJklM7uy.js";var n=(e=>(e.OPEN_AI="open_ai",e.OPEN_AI_COMPATIBLE="open_ai_compatible",e.ANTHROPIC="anthropic",e))(n||{});const r={400:"[400] Bad Request",401:"[401] 提供错误的API密钥 | Incorrect API key provided",403:"[403] 服务器拒绝访问，请稍后再试 | Server refused to access, please try again later",502:"[502] 错误的网关 |  Bad Gateway",503:"[503] 服务器繁忙，请稍后再试 | Server is busy, please try again later",504:"[504] 网关超时 | Gateway Time-out",500:"[500] 内部错误 | Internal Server Error"},i=[{label:"OpenAI",value:"open_ai",url:"https://platform.openai.com/docs/models"},{label:"OpenAI Compatible",value:"open_ai_compatible",url:"https://aihubmix.com/models"},{label:"Anthropic",value:"anthropic",url:"https://docs.anthropic.com/en/docs/about-claude/models"}],l=[{desc:"Claude 3.5 Haiku 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.5 Haiku 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。",label:"Claude 3.5 Haiku",value:"claude-3-5-haiku-20241022",tokens:2e5,vision:!1,functionCall:!0},{desc:"Claude 3.7 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。",label:"Claude 3.7 Sonnet",value:"claude-3-7-sonnet-20250219",tokens:2e5,vision:!0,functionCall:!0}],c="gpt-4o-mini",u=[{desc:"GPT-4o mini是OpenAI在GPT-4 Omni之后推出的最新模型，支持图文输入并输出文本。作为他们最先进的小型模型，它比其他近期的前沿模型便宜很多，并且比GPT-3.5 Turbo便宜超过60%。它保持了最先进的智能，同时具有显著的性价比。GPT-4o mini在MMLU测试中获得了 82% 的得分，目前在聊天偏好上排名高于 GPT-4。",label:"GPT-4o Mini",value:"gpt-4o-mini",tokens:128e3,vision:!0,functionCall:!0},{desc:"",label:"OpenAI o3-mini",value:"o3-mini",vision:!1,tokens:128e3},{desc:"o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。",label:"OpenAI o1-mini",value:"o1-mini",vision:!1,tokens:128e3},{desc:"o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。",label:"OpenAI o1",value:"o1",vision:!1,tokens:128e3},{desc:"ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",label:"GPT-4o",value:"gpt-4o",tokens:128e3,vision:!0,functionCall:!0},{desc:"最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",label:"GPT-4 Turbo",value:"gpt-4-turbo",tokens:128e3,vision:!0,functionCall:!0},{desc:"GPT 3.5 Turbo，适用于各种文本生成和理解任务",label:"GPT-3.5 Turbo",value:"gpt-3.5-turbo",tokens:16385,vision:!1,functionCall:!0}],m=[{label:"Google - Gemini",value:"gemini-2.0-flash",vision:!0,functionCall:!0},{label:"xAI - Grok",value:"grok-2-1212"},{label:"Meta - LLaMA",value:"llama-3.3-70b-versatile"},{label:"同义千问 Qwen 2.5 Max",value:"qwen-max-0125"},{label:"智谱清言 ChatGLM",value:"glm-4-flash"},{label:"深度求索 DeepSeek R1",value:"DeepSeek-R1"},{label:"月之暗面 Moonshot",value:"moonshot-v1-8k"}],p=e=>{switch(e){case"anthropic":return l;case"open_ai":return u;default:return m}},d={};[...l,...u,...m].forEach((e=>{e.vision&&(d[e.value]=!0)}));const h=e("aiSettingsStore",{state:()=>({openAiApiKey:"",openAiApiProxy:"",anthropicApiKey:"",anthropicApiProxy:"",provider:n.OPEN_AI,model:c,stream:!0,currentCharacterId:"default",currentChatHistoryId:"",isSidebarExpand:!0,isEnterSend:!0}),persist:{key:t.LS_KEY_PAGECRAFT_AI_SETTINGS}}),g=e=>{const t=document.querySelector(e);t&&(t.scrollIntoView({behavior:"smooth"}),(async(e,t=3)=>{const a=e.style.backgroundColor;e.style.transition="background-color 0.5s ease";const s=async t=>{e.style.backgroundColor=t,await new Promise((e=>setTimeout(e,300))),e.style.backgroundColor=a,await new Promise((e=>setTimeout(e,300)))};for(let o=0;o<t;o++)await s("var(--primary)");e.style.backgroundColor=a,e.style.transition=""})(t))},T={"o1-mini":!0,o1:!0,"o1-preview":!0},y=()=>{const e=h(),t=async(t={},n,i={})=>{var l,u;const m=e.openAiApiProxy||"https://api.openai.com/v1";(e=>{if(e.messages){let t=e.messages;t=t.filter((e=>"string"!=typeof e.content||!!e.content)),T[e.model]&&(t=t.map((e=>({...e,role:"system"===e.role?"user":e.role})))),e.messages=t}})(t={model:c,stream:e.stream,...t});const p=await fetch(`${m}/chat/completions`,{method:"POST",headers:{Authorization:`Bearer ${e.openAiApiKey}`,"Content-Type":"application/json"},body:JSON.stringify(t),...i}),d=r[p.status];if(d){401===p.status&&(a.emit(s.OPEN_SETTINGS,o.AI),setTimeout((()=>{g('.system-settings .content-wrap [data-key="open_ai"]')}),500));const e=await p.json();throw new Error(`${d}\n\n${e.error.message}`)}if(!p.ok)throw new Error(`HTTP error! status: ${p.status}`);if(t.stream&&"function"==typeof n){const e=p.body.getReader(),t=new TextDecoder("utf-8"),a="";for(;;){const{done:a,value:s}=await e.read();if(a)break;const o=t.decode(s,{stream:!0}).split("\n").filter((e=>""!==e.trim()));for(const e of o)if(e.startsWith("data: ")){const t=e.replace("data: ","");if("[DONE]"!==t)try{const e=null==(u=null==(l=JSON.parse(t).choices[0])?void 0:l.delta)?void 0:u.content;e&&n(e)}catch(h){console.error("Error parsing JSON:",h),console.error("JSON:",t)}}}return a}return await p.json()};return{requestChatStream:t,requestChatMessage:async(e,a={})=>{var s;return((null==(s=(await t({messages:e,stream:!1,...a})).choices[0])?void 0:s.message)||{}).content||""}}};var v=(e=>(e.MESSAGE_START="message_start",e.CONTENT_BLOCK_START="content_block_start",e.PING="ping",e.CONTENT_BLOCK_DELTA="content_block_delta",e.CONTENT_BLOCK_STOP="content_block_stop",e.MESSAGE_DELTA="message_delta",e.MESSAGE_STOP="message_stop",e))(v||{});const b=e=>{const t=e.match(/^data:(image\/(jpeg|png|gif|webp));base64,(.+)$/);if(!t)return null;const a=t[1];return{data:t[3],media_type:a,type:"base64"}},A=()=>{const e=h(),t=async(t={},n,i={})=>{const l=e.anthropicApiProxy||"https://api.anthropic.com/v1/messages";(e=>{e.messages&&e.messages[0]&&"system"===e.messages[0].role&&(e.system=e.messages[0].content,e.messages=e.messages.slice(1),e.messages=e.messages.map((e=>Array.isArray(e.content)?{...e,content:e.content.map((e=>"image_url"===e.type?{type:"image",source:b(e.image_url.url)}:e)).filter((e=>"image"===e.type?!!e.source:!!e.text))}:e)))})(t={model:"claude-3-5-haiku-20241022",stream:e.stream,max_tokens:4096,...t});const c=await fetch(`${l}/v1/messages`,{method:"POST",headers:{"x-api-key":e.anthropicApiKey,"anthropic-version":"2023-06-01","Content-Type":"application/json"},body:JSON.stringify(t),...i}),u=r[c.status];if(u){401===c.status&&(a.emit(s.OPEN_SETTINGS,o.AI),setTimeout((()=>{g('.system-settings .content-wrap [data-key="anthropic"]')}),500));const e=await c.json();throw new Error(`${u}\n\n${e.error.message}`)}if(!c.ok)throw new Error(`HTTP error! status: ${c.status}`);if(!c.body)throw new Error("Response body is null");if(!t.stream)return await c.json();const m=c.body.getReader(),p=new TextDecoder;let d="";return new Promise(((e,t)=>{m.read().then((function a({done:s,value:o}){if(s)e(d);else{if(o){p.decode(o,{stream:!0}).split("\n").forEach((t=>{if(t.startsWith("data: "))try{const a=JSON.parse(t.slice(6));if(a.type===v.CONTENT_BLOCK_DELTA){const e=a.delta.text;d+=e,n&&n(e)}a.type===v.MESSAGE_STOP&&e(d)}catch(a){console.error("Parse error:",a)}}))}m.read().then(a).catch(t)}})).catch(t)}))};return{requestChatStream:t,requestChatMessage:async(e,a={})=>{var s;return(null==(s=(await t({messages:e,stream:!1,...a})).content[0])?void 0:s.text)||""}}},f=()=>{const e=h(),{requestChatStream:t,requestChatMessage:a}=y(),{requestChatStream:s,requestChatMessage:o}=A();return{requestChatStream:(e,a,o,r,i={})=>e===n.ANTHROPIC?s({model:a,messages:o},r,i):t({model:a,messages:o},r,i),requestChatMessage:({provider:t=e.provider,model:s=e.model,messages:r=[]})=>t===n.ANTHROPIC?o(r,{model:s}):a(r,{model:s})}};export{n as A,h as a,y as b,i as c,c as d,A as e,p as g,d as m,f as u};
