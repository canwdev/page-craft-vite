import{bu as e,L as t,y as s,G as a,aM as o}from"./index-Dcsrw7an.js";var r=(e=>(e.OPEN_AI="open_ai",e.ANTHROPIC="anthropic",e))(r||{});const n={400:"[400] Bad Request",401:"[401] 提供错误的API密钥 | Incorrect API key provided",403:"[403] 服务器拒绝访问，请稍后再试 | Server refused to access, please try again later",502:"[502] 错误的网关 |  Bad Gateway",503:"[503] 服务器繁忙，请稍后再试 | Server is busy, please try again later",504:"[504] 网关超时 | Gateway Time-out",500:"[500] 内部错误 | Internal Server Error"},i=[{label:"OpenAI",value:"open_ai",url:"https://platform.openai.com/docs/models"},{label:"Anthropic",value:"anthropic",url:"https://docs.anthropic.com/en/docs/about-claude/models"}],c="claude-3-5-haiku-20241022",l=[{desc:"Claude 3.5 Haiku 是 Anthropic 最快的下一代模型。与 Claude 3 Haiku 相比，Claude 3.5 Haiku 在各项技能上都有所提升，并在许多智力基准测试中超越了上一代最大的模型 Claude 3 Opus。",label:"Claude 3.5 Haiku",value:"claude-3-5-haiku-20241022",tokens:2e5,functionCall:!0},{desc:"Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。",label:"Claude 3.5 Sonnet",value:"claude-3-5-sonnet-20241022",tokens:2e5,vision:!0,functionCall:!0}],u="gpt-4o-mini",m=[{desc:"o1-mini是一款针对编程、数学和科学应用场景而设计的快速、经济高效的推理模型。该模型具有128K上下文和2023年10月的知识截止日期。",label:"OpenAI o1-mini",value:"o1-mini",tokens:128e3},{desc:"o1是OpenAI新的推理模型，适用于需要广泛通用知识的复杂任务。该模型具有128K上下文和2023年10月的知识截止日期。",label:"OpenAI o1-preview",value:"o1-preview",tokens:128e3},{desc:"GPT-4o mini是OpenAI在GPT-4 Omni之后推出的最新模型，支持图文输入并输出文本。作为他们最先进的小型模型，它比其他近期的前沿模型便宜很多，并且比GPT-3.5 Turbo便宜超过60%。它保持了最先进的智能，同时具有显著的性价比。GPT-4o mini在MMLU测试中获得了 82% 的得分，目前在聊天偏好上排名高于 GPT-4。",label:"GPT-4o Mini",value:"gpt-4o-mini",tokens:128e3,vision:!0,functionCall:!0},{desc:"ChatGPT-4o 是一款动态模型，实时更新以保持当前最新版本。它结合了强大的语言理解与生成能力，适合于大规模应用场景，包括客户服务、教育和技术支持。",label:"GPT-4o",value:"gpt-4o",tokens:128e3,vision:!0,functionCall:!0},{desc:"最新的 GPT-4 Turbo 模型具备视觉功能。现在，视觉请求可以使用 JSON 模式和函数调用。 GPT-4 Turbo 是一个增强版本，为多模态任务提供成本效益高的支持。它在准确性和效率之间找到平衡，适合需要进行实时交互的应用程序场景。",label:"GPT-4 Turbo",value:"gpt-4-turbo",tokens:128e3,vision:!0,functionCall:!0},{desc:"GPT 3.5 Turbo，适用于各种文本生成和理解任务",label:"GPT-3.5 Turbo",value:"gpt-3.5-turbo",tokens:16385,functionCall:!0}],p=e=>"anthropic"===e?l:m,d={};[...l,...m].forEach((e=>{e.vision&&(d[e.value]=!0)}));const h=e("aiSettingsStore",{state:()=>({openAiApiKey:"",openAiApiProxy:"",anthropicApiKey:"",anthropicApiProxy:"",provider:r.OPEN_AI,model:u,stream:!0,currentCharacterId:"default",currentChatHistoryId:"",isSidebarExpand:!0,isEnterSend:!0}),persist:{key:t.LS_KEY_PAGECRAFT_AI_SETTINGS}}),y=e=>{const t=document.querySelector(e);t&&(t.scrollIntoView({behavior:"smooth"}),(async(e,t=3)=>{const s=e.style.backgroundColor;e.style.transition="background-color 0.5s ease";const a=async t=>{e.style.backgroundColor=t,await new Promise((e=>setTimeout(e,300))),e.style.backgroundColor=s,await new Promise((e=>setTimeout(e,300)))};for(let o=0;o<t;o++)await a("var(--primary)");e.style.backgroundColor=s,e.style.transition=""})(t))},T={"o1-mini":!0,"o1-preview":!0},g=()=>{const e=h(),t=async(t={},r,i={})=>{var c,l;const m=e.openAiApiProxy||"https://api.openai.com/v1";(e=>{if(e.messages){let t=e.messages;t=t.filter((e=>"string"!=typeof e.content||!!e.content)),T[e.model]&&(t=t.map((e=>({...e,role:"system"===e.role?"user":e.role})))),e.messages=t}})(t={model:u,stream:e.stream,...t});const p=await fetch(`${m}/chat/completions`,{method:"POST",headers:{Authorization:`Bearer ${e.openAiApiKey}`,"Content-Type":"application/json"},body:JSON.stringify(t),...i}),d=n[p.status];if(d){401===p.status&&(s.emit(a.OPEN_SETTINGS,o.AI),setTimeout((()=>{y('.system-settings .content-wrap [data-key="open_ai"]')}),500));const e=await p.json();throw new Error(`${d}\n\n${e.error.message}`)}if(!p.ok)throw new Error(`HTTP error! status: ${p.status}`);if(t.stream&&"function"==typeof r){const e=p.body.getReader(),t=new TextDecoder("utf-8"),s="";for(;;){const{done:s,value:a}=await e.read();if(s)break;const o=t.decode(a,{stream:!0}).split("\n").filter((e=>""!==e.trim()));for(const e of o)if(e.startsWith("data: ")){const t=e.replace("data: ","");if("[DONE]"!==t)try{const e=null==(l=null==(c=JSON.parse(t).choices[0])?void 0:c.delta)?void 0:l.content;e&&r(e)}catch(h){console.error("Error parsing JSON:",h),console.error("JSON:",t)}}}return s}return await p.json()};return{requestChatStream:t,requestChatMessage:async(e,s={})=>{var a;return((null==(a=(await t({messages:e,stream:!1,...s})).choices[0])?void 0:a.message)||{}).content||""}}};var S=(e=>(e.MESSAGE_START="message_start",e.CONTENT_BLOCK_START="content_block_start",e.PING="ping",e.CONTENT_BLOCK_DELTA="content_block_delta",e.CONTENT_BLOCK_STOP="content_block_stop",e.MESSAGE_DELTA="message_delta",e.MESSAGE_STOP="message_stop",e))(S||{});const f=e=>{const t=e.match(/^data:(image\/(jpeg|png|gif|webp));base64,(.+)$/);if(!t)return null;const s=t[1];return{data:t[3],media_type:s,type:"base64"}},A=()=>{const e=h(),t=async(t={},r,i={})=>{const l=e.anthropicApiProxy||"https://api.anthropic.com/v1/messages";(e=>{e.messages&&e.messages[0]&&"system"===e.messages[0].role&&(e.system=e.messages[0].content,e.messages=e.messages.slice(1),e.messages=e.messages.map((e=>Array.isArray(e.content)?{...e,content:e.content.map((e=>"image_url"===e.type?{type:"image",source:f(e.image_url.url)}:e)).filter((e=>"image"===e.type?!!e.source:!!e.text))}:e)))})(t={model:c,stream:e.stream,max_tokens:4096,...t});const u=await fetch(`${l}/v1/messages`,{method:"POST",headers:{"x-api-key":e.anthropicApiKey,"anthropic-version":"2023-06-01","Content-Type":"application/json"},body:JSON.stringify(t),...i}),m=n[u.status];if(m){401===u.status&&(s.emit(a.OPEN_SETTINGS,o.AI),setTimeout((()=>{y('.system-settings .content-wrap [data-key="anthropic"]')}),500));const e=await u.json();throw new Error(`${m}\n\n${e.error.message}`)}if(!u.ok)throw new Error(`HTTP error! status: ${u.status}`);if(!u.body)throw new Error("Response body is null");if(!t.stream)return await u.json();const p=u.body.getReader(),d=new TextDecoder;let h="";return new Promise(((e,t)=>{p.read().then((function s({done:a,value:o}){if(a)e(h);else{if(o){d.decode(o,{stream:!0}).split("\n").forEach((t=>{if(t.startsWith("data: "))try{const s=JSON.parse(t.slice(6));if(s.type===S.CONTENT_BLOCK_DELTA){const e=s.delta.text;h+=e,r&&r(e)}s.type===S.MESSAGE_STOP&&e(h)}catch(s){console.error("Parse error:",s)}}))}p.read().then(s).catch(t)}})).catch(t)}))};return{requestChatStream:t,requestChatMessage:async(e,s={})=>{var a;return(null==(a=(await t({messages:e,stream:!1,...s})).content[0])?void 0:a.text)||""}}},C=()=>{const e=h(),{requestChatStream:t,requestChatMessage:s}=g(),{requestChatStream:a,requestChatMessage:o}=A();return{requestChatStream:(e,s,o,n,i={})=>{switch(e){case r.OPEN_AI:return t({model:s,messages:o},n,i);case r.ANTHROPIC:return a({model:s,messages:o},n,i)}},requestChatMessage:({provider:t=e.provider,model:a=e.model,messages:n=[]})=>{switch(t){case r.OPEN_AI:return s(n,{model:a});case r.ANTHROPIC:return o(n,{model:a})}}}};export{r as A,h as a,c as b,i as c,u as d,g as e,A as f,p as g,d as m,C as u};
